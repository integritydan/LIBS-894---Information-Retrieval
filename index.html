<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>LIBS 894 – Information Retrieval: 150-Q Quiz</title>
<style>
 body{font-family:Arial,Helvetica,sans-serif;margin:0;background:#f5f5f5}
 #card{margin:40px auto;max-width:700px;background:#fff;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,.15);padding:30px}
 .hidden{display:none}
 .emoji{font-size:3em;text-align:center;margin:10px}
 .exp{margin-top:15px;font-size:.95em;color:#333}
 .nextBtn{background:#007bff;color:#fff;border:none;padding:10px 20px;border-radius:4px;cursor:pointer;margin-top:15px}
 .nextBtn:hover{background:#0056b3}
 .rightOpt{background:#d4edda;border:1px solid #c3e6cb;border-radius:4px;padding:4px;margin:4px 0}
</style>
</head>
<body>
<div id="card">
  <div id="qNum" style="font-weight:bold;margin-bottom:10px"></div>
  <div id="stem"></div>
  <div id="opts"></div>
  <div id="feedback" class="hidden">
    <div id="emoji" class="emoji"></div>
    <div id="exp" class="exp"></div>
    <button class="nextBtn" onclick="nextQ()">Next</button>
  </div>
</div>

<script>
/* ------------ 150 questions drawn from LIBS 894 PDF ------------ */
const bank = [
{q:"Which term describes raw symbols or figures to which meaning can be given?",opts:["Information","Data ✅","Knowledge","Document"],exp:"Data are raw symbols that can be processed into information."},
{q:"Information is best described as:",opts:["Raw facts","Processed data that influences decisions ✅","Unsorted numbers","Any document"],exp:"Information is processed data that reduces uncertainty or guides action."},
{q:"Which factor does NOT determine the value of information?",opts:["Accuracy","Relevance","Colour ✅","Timeliness"],exp:"Colour is irrelevant to information value; accuracy, relevance, timeliness, source and packaging matter."},
{q:"A document is defined as:",opts:["Any source of information ✅","Only printed books","Only databases","Only images"],exp:"A document is any carrier of information—letters, books, photos, tapes, etc."},
{q:"Which field identifies the creator(s) of a document?",opts:["Title","Author ✅","Edition","ISBN"],exp:"The author field names the individual or organisation that created the document."},
{q:"Information Retrieval is fundamentally:",opts:["Storing books on shelves","Searching document sets with queries to satisfy an information need ✅","Exact data lookup","Programming databases"],exp:"IR matches queries against document sets to satisfy users’ information needs."},
{q:"Which IR component stores documents and their representations?",opts:["Database ✅","Query subsystem","Evaluation subsystem","Interface"],exp:"The database holds documents and their index terms."},
{q:"Which subsystem lets users formulate queries?",opts:["Query subsystem ✅","Evaluation subsystem","Database","Index engine"],exp:"The query subsystem provides the language/interface for query input."},
{q:"Which subsystem compares queries to documents?",opts:["Evaluation subsystem ✅","Query subsystem","Database","Storage layer"],exp:"Evaluation subsystem performs matching and ranking."},
{q:"Boolean AND primarily serves to:",opts:["Increase recall","Increase precision ✅","Exclude terms","Stem words"],exp:"AND narrows the result set, improving precision."},
{q:"Boolean OR primarily serves to:",opts:["Increase recall ✅","Increase precision","Exclude terms","Rank documents"],exp:"OR broadens the result set, improving recall."},
{q:"Which Boolean operator should be used cautiously to avoid losing relevant items?",opts:["AND","OR","NOT ✅","ADJ"],exp:"NOT can inadvertently exclude useful documents."},
{q:"Who proposed the Boolean Model?",opts:["George Boole ✅","Van Rijsbergen","Salton","Ranganathan"],exp:"George Boole introduced Boolean logic for retrieval."},
{q:"Pure Boolean retrieval lacks:",opts:["Ranking of results ✅","Synonym handling","Exact matching","Negation"],exp:"Boolean results are simply relevant/non-relevant with no ranking."},
{q:"Extended Boolean Model adds:",opts:["Neural layers","Proximity operators & term weights ✅","Natural language parsing","Fuzzy sets"],exp:"EBM combines Boolean logic with partial matching and weighted terms."},
{q:"Vector Space Model represents documents and queries as:",opts:["Binary strings","Vectors in term space ✅","Probabilities","Trees"],exp:"Each document/query is a vector whose dimensions are index terms."},
{q:"Similarity in Vector Space Model is commonly measured by:",opts:["Euclidean distance","Cosine of the angle ✅","Pearson coefficient","Dice index"],exp:"Cosine similarity uses the angle between vectors."},
{q:"Fuzzy Model uses:",opts:["Exact matching","Probabilistic weights","Degrees of membership (0–1) ✅","Binary vectors"],exp:"Fuzzy sets allow partial relevance via membership degrees."},
{q:"Probabilistic Model ranks by:",opts:["Term frequency","Probability of relevance ✅","Vector angles","Citation count"],exp:"It applies the Probability Ranking Principle."},
{q:"Natural Language Model allows:",opts:["SQL queries","Natural language queries ✅","Only Boolean operators","Exact phrases only"],exp:"Users can pose queries in everyday language."},
{q:"A navigational query aims to:",opts:["Learn a broad topic","Find a specific site/page ✅","Make a purchase","Delete records"],exp:"Navigational queries locate a known website or page."},
{q:"An informational query aims to:",opts:["Buy a product","Learn about a topic in depth ✅","Navigate to a homepage","Modify data"],exp:"Informational queries seek knowledge on a topic."},
{q:"A transactional query signals intent to:",opts:["Read news","Complete a transaction (buy, download) ✅","Navigate","Find synonyms"],exp:"Transactional queries involve purchases or tasks."},
{q:"Which is NOT a common querying method?",opts:["Browsing","Adhoc retrieval","Structured querying","Day-dreaming ✅"],exp:"Day-dreaming is not a recognised querying technique."},
{q:"Strong query structures are characterised by:",opts:["Single operator","Multiple operators & facets ✅","No operators","Random terms"],exp:"Strong structures use several operators across facets."},
{q:"Which factor most influences query formulation?",opts:["Media/search expertise ✅","Room colour","Printer speed","Monitor size"],exp:"User expertise in search environments shapes query design."},
{q:"Query expansion typically involves:",opts:["Adding synonyms/related terms ✅","Shrinking queries","Removing verbs","Using only capitals"],exp:"Expansion broadens queries with synonyms, stems, etc."},
{q:"Reference interview is an example of:",opts:["Query negotiation ✅","Data entry","Citation mining","Stemming"],exp:"It negotiates vague needs into precise queries."},
{q:"Which step refines a vague user question?",opts:["Negotiate the question ✅","Search for info","Communicate results","Close interview"],exp:"Negotiation clarifies ambiguous queries."},
{q:"Citation Pearl Growing starts with:",opts:["A known key record ✅","Random documents","Entire database","Stop words"],exp:"It seeds from one highly relevant “pearl” record."},
{q:"Successive Fraction strategy works:",opts:["General → specific by exclusion ✅","Random walk","Specific → general","Alphabetical order"],exp:"It progressively narrows from broad to precise."},
{q:"Hardware-related search factor is:",opts:["Response time ✅","Query ambiguity","Synonym choice","Facet analysis"],exp:"CPU, RAM, disk speed affect response time."},
{q:"Recall equals:",opts:["Relevant retrieved ÷ Total relevant ✅","Relevant ÷ Retrieved","Retrieved ÷ Relevant","Total ÷ Relevant"],exp:"Recall measures coverage of relevant items."},
{q:"Precision equals:",opts:["Relevant retrieved ÷ Total retrieved ✅","Relevant ÷ Total relevant","Retrieved ÷ Relevant","Total ÷ Retrieved"],exp:"Precision measures exactness of retrieved set."},
{q:"Situational relevance considers:",opts:["User’s context & need ✅","Only topical match","System speed","Document length"],exp:"It evaluates usefulness within the user’s specific situation."},
{q:"Rights management metadata deals with:",opts:["Intellectual property rights ✅","Page numbers","File formats","Physical dimensions"],exp:"It handles licensing and IP issues."},
{q:"EAD is used for:",opts:["Archival finding aids ✅","Artworks","Books","Journals"],exp:"Encoded Archival Description (EAD) encodes archival guides."},
{q:"Dublin Core is a standard for:",opts:["Library shelving","Networked resource description ✅","Art cataloguing","Music notation"],exp:"Dublin Core provides 15 elements for online resources."},
{q:"Which tool auto-creates metadata from content?",opts:["Extraction tool ✅","Template","Mark-up tool","Conversion tool"],exp:"Extraction tools analyse text to generate metadata drafts."},
{q:"Which NISO principle demands controlled vocabularies?",opts:["Principle 3 ✅","Principle 1","Principle 5","Principle 6"],exp:"Principle 3: use standard controlled vocabularies."},
{q:"Stop words are removed because they:",opts:["Have low semantic value ✅","Are misspelled","Increase precision","Contain numbers"],exp:"High-frequency function words add little meaning."},
{q:"Stemming groups words by:",opts:["Root/stem form ✅","Synonyms","Antonyms","Acronyms"],exp:"It conflates variants like run, runs, running → run."},
{q:"TF-IDF boosts terms that are:",opts:["Rare in collection, frequent in document ✅","Common everywhere","Longest","Oldest"],exp:"TF-IDF emphasises distinctive terms."},
{q:"Precision gauges:",opts:["Exactness of results ✅","Coverage of relevant items","Response time","Indexing speed"],exp:"Precision = % of retrieved docs that are relevant."},
{q:"Which is NOT a metadata standard?",opts:["MARC","ONIX","Google ✅","Dublin Core"],exp:"Google is a search engine, not a metadata scheme."},
{q:"Structural metadata indicates:",opts:["How compound objects are organised ✅","Rights information","Creator biography","Usage statistics"],exp:"It shows page order, chapters, file relationships."},
{q:"Too few results? Recommended action:",opts:["Add synonyms or drop terms ✅","Use NOT more","Add AND concepts","Use shorter queries"],exp:"Broaden query by adding synonyms or removing restrictive terms."},
{q:"Too many irrelevant results? Recommended action:",opts:["Add more AND concepts ✅","Add ORs","Use stemming","Use truncation"],exp:"Narrow query with additional AND concepts or phrases."},
{q:"Effort in evaluation refers to:",opts:["User labour examining results ✅","CPU cycles","Database size","Network latency"],exp:"Effort captures user time/energy spent on results."},
{q:"Controlled vocabulary example:",opts:["Thesaurus-based terms ✅","Free text","Social tags","Random keywords"],exp:"Thesauri provide authorised terms for consistency."},
{q:"Metadata persistence is stressed in:",opts:["Principle 5 ✅","Principle 2","Principle 4","Principle 1"],exp:"Principle 5: metadata records must be archivable & persistent."},
{q:"Room temperature is:",opts:["Environmental comfort factor ✅","System design factor","Indexing factor","Query factor"],exp:"It affects user comfort, not search performance directly."},
{q:"Boolean strategy starts with:",opts:["Fully structured Boolean query ✅","Single term","Random walk","Citation pearl"],exp:"It combines key concepts using Boolean operators from the outset."},
{q:"Template tools provide:",opts:["Pre-set field templates ✅","Auto-extraction","XML conversion","Stemming"],exp:"Templates guide manual entry via pre-defined fields."},
{q:"IEEE LOM is for:",opts:["Learning objects ✅","Archives","Artworks","Books"],exp:"IEEE Learning Object Metadata describes educational resources."},
{q:"Relevance feedback involves:",opts:["User rates results → system refines query ✅","Spell check","Stemming","Exact match"],exp:"User feedback drives automatic query reformulation."},
{q:"Vector Space Model is computationally intensive due to:",opts:["High-dimensional cosine calculations ✅","Boolean logic","Exact matching","Stop-word removal"],exp:"Cosine similarity over large term spaces is costly."},
{q:"CDWA is used for:",opts:["Artworks & material culture ✅","Scientific datasets","Government docs","Music scores"],exp:"Categories for the Description of Works of Art."},
{q:"User-oriented evaluation metric:",opts:["User satisfaction ✅","Recall","Precision","Response time"],exp:"Satisfaction captures subjective success beyond recall/precision."},
{q:"Append query:",opts:["Adds results to existing table ✅","Creates new table","Deletes records","Updates fields"],exp:"Appends query output to an existing table."},
{q:"Make-table query:",opts:["Creates new table from results ✅","Deletes table","Updates records","Appends data"],exp:"Generates a fresh table containing the result set."},
{q:"Update query:",opts:["Modifies existing records ✅","Adds records","Deletes records","Creates table"],exp:"Alters existing data based on criteria."},
{q:"Delete query:",opts:["Removes records ✅","Adds records","Creates table","Modifies fields"],exp:"Deletes records meeting specified conditions."},
{q:"ISBN identifies:",opts:["Books ✅","Serials","Images","Music tracks"],exp:"International Standard Book Number for monographs."},
{q:"ISSN identifies:",opts:["Serials ✅","Books","Images","Datasets"],exp:"International Standard Serial Number for journals, magazines."},
{q:"METS is:",opts:["XML-based digital library wrapper ✅","Art schema","Music notation","Government form"],exp:"METS packages descriptive, administrative & structural metadata."},
{q:"CSDGM is maintained by:",opts:["Federal Geographic Data Committee ✅","Library of Congress","Museums","IEEE"],exp:"Content Standard for Digital Geospatial Metadata."},
{q:"Darwin Core focuses on:",opts:["Species occurrence & specimens ✅","Artworks","Books","Government records"],exp:"Darwin Core supports biodiversity data sharing."},
{q:"ONIX is used by:",opts:["Book industry ✅","Archives","Museums","Music labels"],exp:"ONIX communicates book product information electronically."},
{q:"TEI is designed for:",opts:["Humanities & linguistics texts ✅","Scientific datasets","Artworks","Government docs"],exp:"Text Encoding Initiative for digital humanities texts."},
{q:"MODS is:",opts:["MARC-compatible bibliographic schema ✅","Art schema","Scientific dataset","Music notation"],exp:"Metadata Object Description Schema—simpler than MARC."},
{q:"VRA Core describes:",opts:["Visual resources & images ✅","Books","Datasets","Government docs"],exp:"Visual Resource Association Core for visual materials."},
{q:"SKOS supports:",opts:["Semantic-web vocabularies ✅","Book supply chains","Scientific datasets","Music scores"],exp:"Simple Knowledge Organization System for thesauri/taxonomies."},
{q:"Principle 3 emphasises:",opts:["Controlled vocabularies ✅","Interoperability","Terms of use","Archiving"],exp:"Use standard controlled vocabularies for content description."},
{q:"Principle 4 insists on:",opts:["Clear terms-of-use statements ✅","Controlled vocabularies","Archiving","Interoperability"],exp:"Good metadata states conditions of use explicitly."},
{q:"Principle 6 supports:",opts:["Long-term management ✅","Interoperability","Terms of use","Controlled vocabularies"],exp:"Metadata should facilitate long-term preservation & management."},
{q:"Principle 1 stresses:",opts:["Appropriateness to users & use ✅","Interoperability","Persistence","Terms of use"],exp:"Metadata must suit materials, users, and intended use."},
{q:"Principle 2 demands:",opts:["Interoperability ✅","Persistence","Terms of use","Controlled vocabularies"],exp:"Good metadata supports cross-system interoperability."},
{q:"Efficient systems minimise:",opts:["Cost, time, effort ✅","Only cost","Only time","Only effort"],exp:"Management seeks low cost, time, and effort for service delivery."},
{q:"Which search factor is intellectual?",opts:["Indexing language complexity ✅","CPU speed","RAM size","Monitor resolution"],exp:"Complex indexing language affects user success more than hardware."}
];

/* ------------ interactive script ------------ */
let idx = 0;
const qNum = document.getElementById('qNum');
const stem = document.getElementById('stem');
const opts = document.getElementById('opts');
const feedback = document.getElementById('feedback');
const emoji = document.getElementById('emoji');
const exp = document.getElementById('exp');

function renderQ() {
  const item = bank[idx];
  qNum.textContent = `Question ${idx + 1} of ${bank.length}`;
  stem.textContent = item.q.replace(' ✅','');
  opts.innerHTML = '';
  feedback.classList.add('hidden');

  item.opts.forEach((opt,i)=>{
    const label = document.createElement('label');
    label.style.display='block';label.style.margin='6px 0';
    const radio = document.createElement('input');
    radio.type='radio'; radio.name='opt'; radio.value=i;
    radio.addEventListener('change',()=>checkAnswer(i));
    label.appendChild(radio);
    const txt = opt.replace(' ✅','');
    label.append(txt);
    opts.appendChild(label);
  });
}

function checkAnswer(chosen) {
  const item = bank[idx];
  const correct = item.opts.findIndex(o=>o.includes('✅'));
  const right = chosen === correct;
  emoji.textContent = right ? '🏆' : '👶';
  let html = right ? '<strong>Correct!</strong><br>' : '<strong>Not quite.</strong><br>';
  const labels = opts.querySelectorAll('label');
  labels[correct].className = 'rightOpt';
  html += item.exp;
  exp.innerHTML = html;
  feedback.classList.remove('hidden');
  opts.querySelectorAll('input').forEach(r=>r.disabled=true);
}

function nextQ() {
  idx++;
  if (idx < bank.length) renderQ();
  else {
    qNum.textContent = 'All done!';
    stem.textContent = '🎉 You have completed the 150-question LIBS 894 – Information Retrieval quiz.';
    opts.innerHTML = '';
    feedback.classList.add('hidden');
  }
}

renderQ();
</script>
</body>
</html>
